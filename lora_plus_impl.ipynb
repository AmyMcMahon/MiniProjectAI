{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49300ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/dervlagargan/Documents/College/CS6514/AI/.venv/lib/python3.13/site-packages (4.57.1)\n",
      "Requirement already satisfied: datasets in /Users/dervlagargan/Documents/College/CS6514/AI/.venv/lib/python3.13/site-packages (4.2.0)\n",
      "Requirement already satisfied: scikit-learn in /Users/dervlagargan/Documents/College/CS6514/AI/.venv/lib/python3.13/site-packages (1.7.2)\n",
      "Requirement already satisfied: pandas in /Users/dervlagargan/Documents/College/CS6514/AI/.venv/lib/python3.13/site-packages (2.3.3)\n",
      "Requirement already satisfied: torch in /Users/dervlagargan/Documents/College/CS6514/AI/.venv/lib/python3.13/site-packages (2.8.0)\n",
      "Requirement already satisfied: peft in /Users/dervlagargan/Documents/College/CS6514/AI/.venv/lib/python3.13/site-packages (0.17.1)\n",
      "Requirement already satisfied: bitsandbytes in /Users/dervlagargan/Documents/College/CS6514/AI/.venv/lib/python3.13/site-packages (0.42.0)\n",
      "Requirement already satisfied: filelock in /Users/dervlagargan/Documents/College/CS6514/AI/.venv/lib/python3.13/site-packages (from transformers) (3.20.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /Users/dervlagargan/Documents/College/CS6514/AI/.venv/lib/python3.13/site-packages (from transformers) (0.35.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/dervlagargan/Documents/College/CS6514/AI/.venv/lib/python3.13/site-packages (from transformers) (2.3.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/dervlagargan/Documents/College/CS6514/AI/.venv/lib/python3.13/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/dervlagargan/Documents/College/CS6514/AI/.venv/lib/python3.13/site-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/dervlagargan/Documents/College/CS6514/AI/.venv/lib/python3.13/site-packages (from transformers) (2025.9.18)\n",
      "Requirement already satisfied: requests in /Users/dervlagargan/Documents/College/CS6514/AI/.venv/lib/python3.13/site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /Users/dervlagargan/Documents/College/CS6514/AI/.venv/lib/python3.13/site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/dervlagargan/Documents/College/CS6514/AI/.venv/lib/python3.13/site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/dervlagargan/Documents/College/CS6514/AI/.venv/lib/python3.13/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/dervlagargan/Documents/College/CS6514/AI/.venv/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/dervlagargan/Documents/College/CS6514/AI/.venv/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/dervlagargan/Documents/College/CS6514/AI/.venv/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /Users/dervlagargan/Documents/College/CS6514/AI/.venv/lib/python3.13/site-packages (from datasets) (21.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /Users/dervlagargan/Documents/College/CS6514/AI/.venv/lib/python3.13/site-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: httpx<1.0.0 in /Users/dervlagargan/Documents/College/CS6514/AI/.venv/lib/python3.13/site-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: xxhash in /Users/dervlagargan/Documents/College/CS6514/AI/.venv/lib/python3.13/site-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /Users/dervlagargan/Documents/College/CS6514/AI/.venv/lib/python3.13/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /Users/dervlagargan/Documents/College/CS6514/AI/.venv/lib/python3.13/site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (3.13.0)\n",
      "Requirement already satisfied: anyio in /Users/dervlagargan/Documents/College/CS6514/AI/.venv/lib/python3.13/site-packages (from httpx<1.0.0->datasets) (4.11.0)\n",
      "Requirement already satisfied: certifi in /Users/dervlagargan/Documents/College/CS6514/AI/.venv/lib/python3.13/site-packages (from httpx<1.0.0->datasets) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/dervlagargan/Documents/College/CS6514/AI/.venv/lib/python3.13/site-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
      "Requirement already satisfied: idna in /Users/dervlagargan/Documents/College/CS6514/AI/.venv/lib/python3.13/site-packages (from httpx<1.0.0->datasets) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/dervlagargan/Documents/College/CS6514/AI/.venv/lib/python3.13/site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /Users/dervlagargan/Documents/College/CS6514/AI/.venv/lib/python3.13/site-packages (from scikit-learn) (1.16.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/dervlagargan/Documents/College/CS6514/AI/.venv/lib/python3.13/site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/dervlagargan/Documents/College/CS6514/AI/.venv/lib/python3.13/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/dervlagargan/Documents/College/CS6514/AI/.venv/lib/python3.13/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/dervlagargan/Documents/College/CS6514/AI/.venv/lib/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/dervlagargan/Documents/College/CS6514/AI/.venv/lib/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: setuptools in /Users/dervlagargan/Documents/College/CS6514/AI/.venv/lib/python3.13/site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/dervlagargan/Documents/College/CS6514/AI/.venv/lib/python3.13/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in /Users/dervlagargan/Documents/College/CS6514/AI/.venv/lib/python3.13/site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /Users/dervlagargan/Documents/College/CS6514/AI/.venv/lib/python3.13/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: psutil in /Users/dervlagargan/Documents/College/CS6514/AI/.venv/lib/python3.13/site-packages (from peft) (7.1.0)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /Users/dervlagargan/Documents/College/CS6514/AI/.venv/lib/python3.13/site-packages (from peft) (1.11.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Users/dervlagargan/Documents/College/CS6514/AI/.venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /Users/dervlagargan/Documents/College/CS6514/AI/.venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/dervlagargan/Documents/College/CS6514/AI/.venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/dervlagargan/Documents/College/CS6514/AI/.venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/dervlagargan/Documents/College/CS6514/AI/.venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/dervlagargan/Documents/College/CS6514/AI/.venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/dervlagargan/Documents/College/CS6514/AI/.venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.22.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/dervlagargan/Documents/College/CS6514/AI/.venv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/dervlagargan/Documents/College/CS6514/AI/.venv/lib/python3.13/site-packages (from requests->transformers) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/dervlagargan/Documents/College/CS6514/AI/.venv/lib/python3.13/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/dervlagargan/Documents/College/CS6514/AI/.venv/lib/python3.13/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/dervlagargan/Documents/College/CS6514/AI/.venv/lib/python3.13/site-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/dervlagargan/Documents/College/CS6514/AI/.venv/lib/python3.13/site-packages (from jinja2->torch) (3.0.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets scikit-learn pandas torch peft bitsandbytes==0.35.4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc7a832a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dervlagargan/Documents/College/CS6514/AI/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA SETUP: Required library version not found: libsbitsandbytes_cpu.so. Maybe you need to compile it from source?\n",
      "CUDA SETUP: Defaulting to libbitsandbytes.so...\n",
      "\n",
      "================================================ERROR=====================================\n",
      "CUDA SETUP: CUDA detection failed! Possible reasons:\n",
      "1. CUDA driver not installed\n",
      "2. CUDA not installed\n",
      "3. You have multiple conflicting CUDA libraries\n",
      "4. Required library not pre-compiled for this bitsandbytes release!\n",
      "CUDA SETUP: If you compiled from source, try again with `make CUDA_VERSION=DETECTED_CUDA_VERSION` for example, `make CUDA_VERSION=113`.\n",
      "================================================================================\n",
      "\n",
      "CUDA SETUP: Problem: The main issue seems to be that the main CUDA library was not detected.\n",
      "CUDA SETUP: Solution 1): Your paths are probably not up-to-date. You can update them via: sudo ldconfig.\n",
      "CUDA SETUP: Solution 2): If you do not have sudo rights, you can do the following:\n",
      "CUDA SETUP: Solution 2a): Find the cuda library via: find / -name libcuda.so 2>/dev/null\n",
      "CUDA SETUP: Solution 2b): Once the library is found add it to the LD_LIBRARY_PATH: export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:FOUND_PATH_FROM_2a\n",
      "CUDA SETUP: Solution 2c): For a permanent solution add the export from 2b into your .bashrc file, located at ~/.bashrc\n",
      "CUDA SETUP: Required library version not found: libsbitsandbytes_cpu.so. Maybe you need to compile it from source?\n",
      "CUDA SETUP: Defaulting to libbitsandbytes.so...\n",
      "\n",
      "================================================ERROR=====================================\n",
      "CUDA SETUP: CUDA detection failed! Possible reasons:\n",
      "1. CUDA driver not installed\n",
      "2. CUDA not installed\n",
      "3. You have multiple conflicting CUDA libraries\n",
      "4. Required library not pre-compiled for this bitsandbytes release!\n",
      "CUDA SETUP: If you compiled from source, try again with `make CUDA_VERSION=DETECTED_CUDA_VERSION` for example, `make CUDA_VERSION=113`.\n",
      "================================================================================\n",
      "\n",
      "CUDA SETUP: Problem: The main issue seems to be that the main CUDA library was not detected.\n",
      "CUDA SETUP: Solution 1): Your paths are probably not up-to-date. You can update them via: sudo ldconfig.\n",
      "CUDA SETUP: Solution 2): If you do not have sudo rights, you can do the following:\n",
      "CUDA SETUP: Solution 2a): Find the cuda library via: find / -name libcuda.so 2>/dev/null\n",
      "CUDA SETUP: Solution 2b): Once the library is found add it to the LD_LIBRARY_PATH: export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:FOUND_PATH_FROM_2a\n",
      "CUDA SETUP: Solution 2c): For a permanent solution add the export from 2b into your .bashrc file, located at ~/.bashrc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dervlagargan/Documents/College/CS6514/AI/.venv/lib/python3.13/site-packages/bitsandbytes/cextension.py:127: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from datasets import Dataset\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments, EvalPrediction\n",
    "import torch\n",
    "import time\n",
    "from peft import LoraConfig, TaskType, get_peft_model\n",
    "from peft.optimizers import create_loraplus_optimizer\n",
    "import bitsandbytes as bnb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66908410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  humor\n",
      "0  Joe biden rules out 2020 bid: 'guys, i'm not r...      0\n",
      "1  Watch: darvish gave hitter whiplash with slow ...      0\n",
      "2  What do you call a turtle without its shell? d...      1\n",
      "3      5 reasons the 2016 election feels so personal      0\n",
      "4  Pasco police shot mexican migrant from behind,...      0\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "df = pd.read_csv(\"data/dataset.csv\")\n",
    "df[\"humor\"] = df[\"humor\"].astype(int)\n",
    "print(df.head())\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df[\"humor\"])\n",
    "train_ds = Dataset.from_pandas(train_df)\n",
    "test_ds = Dataset.from_pandas(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77f648e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 160000/160000 [00:25<00:00, 6175.60 examples/s]\n",
      "Map: 100%|██████████| 40000/40000 [00:06<00:00, 6251.88 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "def tokenize_fn(batch):\n",
    "    return tokenizer(batch[\"text\"], truncation=True, padding=\"max_length\", max_length=64)\n",
    "\n",
    "train_ds = train_ds.map(tokenize_fn, batched=True)\n",
    "test_ds = test_ds.map(tokenize_fn, batched=True)\n",
    "train_ds = train_ds.rename_column(\"humor\", \"labels\")\n",
    "test_ds = test_ds.rename_column(\"humor\", \"labels\")\n",
    "\n",
    "train_ds.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "test_ds.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bae07f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2).to(device)\n",
    "\n",
    "r = 4\n",
    "lora_config = LoraConfig(task_type=TaskType.SEQ_CLS, \n",
    "                         r=r,\n",
    "                         lora_alpha=1, \n",
    "                         lora_dropout=0.1)\n",
    "\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "optimizer = create_loraplus_optimizer(\n",
    "    model=model,\n",
    "    optimizer_cls=bnb.optim.Adam8bit,\n",
    "    lr=5e-5,\n",
    "    loraplus_lr_ratio=16,\n",
    ")\n",
    "scheduler = None\n",
    "\n",
    "def compute_metrics(p: EvalPrediction):\n",
    "    preds = p.predictions.argmax(-1)\n",
    "    labels = p.label_ids\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(labels, preds),\n",
    "        \"f1\": f1_score(labels, preds),\n",
    "        \"precision\": precision_score(labels, preds),\n",
    "        \"recall\": recall_score(labels, preds)\n",
    "    }\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./lora-bert-humor\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    num_train_epochs=3,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=50,\n",
    "    fp16=False,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=test_ds,\n",
    "    compute_metrics=compute_metrics,\n",
    "    optimizers=(optimizer, scheduler),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3143aa09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dervlagargan/Documents/College/CS6514/AI/.venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'str2optimizer32bit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch.cuda.is_available():\n\u001b[32m      3\u001b[39m     torch.cuda.reset_peak_memory_stats()\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m end_time = time.time()\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch.cuda.is_available():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/College/CS6514/AI/.venv/lib/python3.13/site-packages/transformers/trainer.py:2325\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n\u001b[32m   2323\u001b[39m         hf_hub_utils.enable_progress_bars()\n\u001b[32m   2324\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2325\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2326\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2327\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2328\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2329\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2330\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/College/CS6514/AI/.venv/lib/python3.13/site-packages/transformers/trainer.py:2740\u001b[39m, in \u001b[36mTrainer._inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n\u001b[32m   2737\u001b[39m     context = implicit_replication\n\u001b[32m   2739\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[32m-> \u001b[39m\u001b[32m2740\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2742\u001b[39m \u001b[38;5;28mself\u001b[39m.control = \u001b[38;5;28mself\u001b[39m.callback_handler.on_optimizer_step(args, \u001b[38;5;28mself\u001b[39m.state, \u001b[38;5;28mself\u001b[39m.control)\n\u001b[32m   2744\u001b[39m \u001b[38;5;66;03m# get leaning rate before update\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/College/CS6514/AI/.venv/lib/python3.13/site-packages/accelerate/optimizer.py:179\u001b[39m, in \u001b[36mAcceleratedOptimizer.step\u001b[39m\u001b[34m(self, closure)\u001b[39m\n\u001b[32m    177\u001b[39m         \u001b[38;5;28mself\u001b[39m._accelerate_step_called = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m179\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.accelerator_state.distributed_type == DistributedType.XLA:\n\u001b[32m    181\u001b[39m     \u001b[38;5;28mself\u001b[39m.gradient_state.is_xla_gradients_synced = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/College/CS6514/AI/.venv/lib/python3.13/site-packages/torch/optim/lr_scheduler.py:133\u001b[39m, in \u001b[36mLRScheduler.__init__.<locals>.patch_track_step_called.<locals>.wrap_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    131\u001b[39m opt = opt_ref()\n\u001b[32m    132\u001b[39m opt._opt_called = \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m133\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__get__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__class__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/College/CS6514/AI/.venv/lib/python3.13/site-packages/torch/optim/optimizer.py:516\u001b[39m, in \u001b[36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    511\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    512\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    513\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    514\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m516\u001b[39m out = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    517\u001b[39m \u001b[38;5;28mself\u001b[39m._optimizer_step_code()\n\u001b[32m    519\u001b[39m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/College/CS6514/AI/.venv/lib/python3.13/site-packages/torch/utils/_contextlib.py:120\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/College/CS6514/AI/.venv/lib/python3.13/site-packages/bitsandbytes/optim/optimizer.py:265\u001b[39m, in \u001b[36mOptimizer8bit.step\u001b[39m\u001b[34m(self, closure)\u001b[39m\n\u001b[32m    262\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(state) == \u001b[32m0\u001b[39m:\n\u001b[32m    263\u001b[39m             \u001b[38;5;28mself\u001b[39m.init_state(group, p, gindex, pindex)\n\u001b[32m--> \u001b[39m\u001b[32m265\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mupdate_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/College/CS6514/AI/.venv/lib/python3.13/site-packages/torch/utils/_contextlib.py:120\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/College/CS6514/AI/.venv/lib/python3.13/site-packages/bitsandbytes/optim/optimizer.py:458\u001b[39m, in \u001b[36mOptimizer2State.update_step\u001b[39m\u001b[34m(self, group, p, gindex, pindex)\u001b[39m\n\u001b[32m    455\u001b[39m     gnorm_scale = \u001b[32m1.0\u001b[39m\n\u001b[32m    457\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m state[\u001b[33m\"\u001b[39m\u001b[33mstate1\u001b[39m\u001b[33m\"\u001b[39m].dtype == torch.float:\n\u001b[32m--> \u001b[39m\u001b[32m458\u001b[39m     \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimizer_update_32bit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    459\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptimizer_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    460\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    461\u001b[39m \u001b[43m        \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    462\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstate1\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    463\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbetas\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    464\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43meps\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    465\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    466\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    467\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstate2\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    468\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbetas\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    469\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweight_decay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    470\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgnorm_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    471\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43munorm_vec\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_unorm\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m>\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    472\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_unorm\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_unorm\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    473\u001b[39m \u001b[43m        \u001b[49m\u001b[43mskip_zeros\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mskip_zeros\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    474\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m state[\u001b[33m\"\u001b[39m\u001b[33mstate1\u001b[39m\u001b[33m\"\u001b[39m].dtype == torch.uint8 \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m config[\u001b[33m\"\u001b[39m\u001b[33mblock_wise\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m    477\u001b[39m     F.optimizer_update_8bit(\n\u001b[32m    478\u001b[39m         \u001b[38;5;28mself\u001b[39m.optimizer_name,\n\u001b[32m    479\u001b[39m         grad,\n\u001b[32m   (...)\u001b[39m\u001b[32m    499\u001b[39m         max_unorm=config[\u001b[33m\"\u001b[39m\u001b[33mmax_unorm\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    500\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/College/CS6514/AI/.venv/lib/python3.13/site-packages/bitsandbytes/functional.py:658\u001b[39m, in \u001b[36moptimizer_update_32bit\u001b[39m\u001b[34m(optimizer_name, g, p, state1, beta1, eps, step, lr, state2, beta2, weight_decay, gnorm_scale, unorm_vec, max_unorm, skip_zeros)\u001b[39m\n\u001b[32m    655\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m max_unorm > \u001b[32m0.0\u001b[39m:\n\u001b[32m    656\u001b[39m     param_norm = torch.norm(p.data.float())\n\u001b[32m--> \u001b[39m\u001b[32m658\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m optimizer_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[43mstr2optimizer32bit\u001b[49m:\n\u001b[32m    659\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[32m    660\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mOptimizer not implemented: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moptimizer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. Choices: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m,\u001b[39m\u001b[33m\"\u001b[39m.join(str2optimizer32bit.keys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m    661\u001b[39m     )\n\u001b[32m    663\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m g.dtype == torch.float32 \u001b[38;5;129;01mand\u001b[39;00m state1.dtype == torch.float32:\n",
      "\u001b[31mNameError\u001b[39m: name 'str2optimizer32bit' is not defined"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "trainer.train()\n",
    "end_time = time.time()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    peak_gpu_memory_gb = torch.cuda.max_memory_allocated() / 1024**3 \n",
    "\n",
    "results = trainer.evaluate()\n",
    "\n",
    "print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Peak GPU memory usage: {peak_gpu_memory_gb:.2f} GB\")\n",
    "print(\"Performance metrics:\", results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
